# ğŸ” Bidirectional ClickHouse & Flat File Data Ingestion Tool

A full-stack web application that enables seamless data transfer between ClickHouse databases and CSV files in both directions.

## ğŸ“Œ Project Overview

This tool provides a user-friendly interface for:
- Exporting data from ClickHouse databases to CSV files
- Importing data from CSV files into ClickHouse tables
- Previewing and selecting columns
- Handling JWT authentication for secure ClickHouse connections
- Monitoring ingestion progress and record counts

## ğŸš€ Features

- ğŸ”„ **Bidirectional Data Flow**:
  - Export data from **ClickHouse â†’ CSV**
  - Import data from **CSV â†’ ClickHouse**
- âœ… **JWT Authentication** for ClickHouse connections
- ğŸ“‚ **CSV File Upload & Download** support
- ğŸ“‹ **Schema Discovery & Column Selection**:
  - View tables and columns from ClickHouse
  - Preview column headers from uploaded CSV
- ğŸ” **Data Preview** before ingestion
- ğŸ“Š **Progress Indicator** and **record count display**
- ğŸ” Support for **JOIN queries** between multiple ClickHouse tables
- ğŸš« **Error Handling** with user-friendly messages

## ğŸ§‘â€ğŸ’» Technologies Used

### âš™ï¸ Backend
- **Node.js & Express**: Web server framework
- **@apla/clickhouse**: ClickHouse client for Node.js
- **jsonwebtoken**: For handling JWT tokens
- **csv-parser & fast-csv**: For reading/writing CSV files
- **multer**: For handling file uploads
- **cors & dotenv**: Utility libraries

### ğŸ’» Frontend
- **React**: UI framework
- **axios**: For API calls
- **react-dropzone**: For file uploads
- **react-toastify**: For status messages

## ğŸ“‚ Project Structure

```
clickhouse-flatfile-ingestion-tool/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ server.js                # Main server entry point
â”‚   â”œâ”€â”€ config.js                # Configuration settings
â”‚   â”œâ”€â”€ routes/                  # API routes
â”‚   â”‚   â”œâ”€â”€ clickhouse.routes.js # ClickHouse connections and queries
â”‚   â”‚   â”œâ”€â”€ csv.routes.js        # CSV upload and download
â”‚   â”‚   â””â”€â”€ index.js             # Route aggregator
â”‚   â”œâ”€â”€ controllers/             # Business logic
â”‚   â”‚   â”œâ”€â”€ clickhouse.controller.js
â”‚   â”‚   â”œâ”€â”€ csv.controller.js
â”‚   â”‚   â””â”€â”€ ingestion.controller.js
â”‚   â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”‚   â”œâ”€â”€ csv-parser.js
â”‚   â”‚   â”œâ”€â”€ clickhouse-client.js
â”‚   â”‚   â””â”€â”€ auth-helper.js
â”‚   â””â”€â”€ data/
â”‚       â””â”€â”€ uploads/             # Temporary storage for uploaded files
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â”œâ”€â”€ index.js
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ConnectionForm.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ColumnSelector.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploader.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressIndicator.jsx
â”‚   â”‚   â”‚   â””â”€â”€ TableViewer.jsx
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ClickHouseToCSV.jsx
â”‚   â”‚   â”‚   â””â”€â”€ CSVToClickHouse.jsx
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js
â”‚   â”‚   â”‚   â”œâ”€â”€ clickhouse.service.js
â”‚   â”‚   â”‚   â””â”€â”€ csv.service.js
â”‚   â”‚   â””â”€â”€ styles/
â”‚   â”‚       â”œâ”€â”€ main.css
â”‚   â”‚       â””â”€â”€ components/
â”‚
â”œâ”€â”€ testdata/                    # Sample data for testing
â”‚   â”œâ”€â”€ uk_price_paid.csv
â”‚   â””â”€â”€ sample_output.csv
â”‚
â”œâ”€â”€ package.json
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ docker-compose.yml          # For local ClickHouse setup
```

## ğŸ–¼ï¸ User Interface (UI) Flow

1. **Select Source**: Choose "ClickHouse" or "Flat File"
2. **Provide Connection Details** (ClickHouse host, port, user, JWT, etc.)
3. **Load Schema**: Fetch tables or columns
4. **Select Columns**: Choose which columns to ingest
5. **Choose Target**: Where the data should go (CSV or ClickHouse)
6. **Start Ingestion**
7. **View Results**: Ingestion complete message + record count

## ğŸ”§ Setup Instructions

### ğŸ–¥ï¸ Prerequisites

- Node.js (v14+) and npm
- Docker (for running ClickHouse locally if needed)
- Git

### ğŸ“ Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/v-a-dinesh/Bidirectional-ClickHouse-Flat-File-Data-Ingestion-Tool.git
   cd Bidirectional-ClickHouse-Flat-File-Data-Ingestion-Tool
   ```

2. **Backend Setup**
   ```bash
   cd .\Data-Ingestion-Tool-Server\
   npm install
   ```

3. **Create a .env file in the backend directory**
   ```
   PORT=5000
   CLICKHOUSE_DEFAULT_HOST=localhost
   CLICKHOUSE_DEFAULT_PORT=8123
   UPLOAD_DIR=./data/uploads
   ```

4. **Start the Backend Server**
   ```bash
   npm start
   # or for development with auto-restart:
   npm run dev
   ```
   Backend will run on: http://localhost:5000

5. **Frontend Setup**
   ```bash
   cd .\Data-Ingestion-Tool-Client\
   npm install
   ```

6. **Start the Frontend App**
   ```bash
   npm start
   ```
   Frontend will be accessible at: http://localhost:3000

### ğŸ³ Running ClickHouse Locally with Docker

```bash
# Start ClickHouse server
docker-compose up -d
```

The ClickHouse server will be available at:
- HTTP interface: http://localhost:8123
- Native interface: localhost:9000

Default credentials:
- Username: default
- Password: (empty)

## ğŸ§ª Testing with Sample Data

The `testdata` directory contains sample CSV files for testing the application:
- `uk_price_paid.csv`: Sample dataset for importing into ClickHouse
- `sample_output.csv`: Example of exported data format

## ğŸ“ Usage Examples

### Example 1: CSV to ClickHouse
1. Select "Flat File" as source
2. Upload CSV file
3. Preview columns and select columns to import
4. Enter ClickHouse connection details
5. Select target table or create new one
6. Start ingestion

### Example 2: ClickHouse to CSV
1. Select "ClickHouse" as source
2. Enter connection details and authenticate
3. Select table and columns to export
4. Choose CSV export options (delimiter, header, etc.)
5. Start export
6. Download the generated CSV file

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“§ Contact

For questions or support, please open an issue in the GitHub repository.